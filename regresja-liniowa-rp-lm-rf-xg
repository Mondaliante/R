#nie gwarantuje, że to jest dobrze xD robione troche na czuja z dodaniem xgboosta, jakby jutro nim zaskoczył. Strojenie może zająć trochę czasu więc
# jak coś olać. Trzeba rozjebać R, a nie się rozjebać

#instalujemy pakiety
library(MASS)
library(dplyr)
library(tidyr)
library(ggplot2)
library(mlr3verse)
library(corrplot)
library(rpart)
library(partykit)
library(lubridate) 
library(DataExplorer)
library(ranger) 
library(simputation)

#ujednolicamy generator liczb losowych
RNGkind(kind = "Mersenne-Twister", sample.kind = "Rejection")

# 1 #### 
# Zbuduj model drzewa (rpart), w którym zmienna celu to x2 a predyktory to 
# zmienne x5 - x13. Za pomocą tego modelu dokonaj predykcji na danych 
# treningowych i oszacuj wartość błędu MAE.

# 2 #### 
# Porównaj za pomocą kroswalidacji wcześniejszy model z modelem liniowym na 
# podstawie błędu MAE. Predyktorami w tym drugim modelu też mają być 
# zmienne x5 - x13.

#spróbujemy porównać sobie 4 learnery, rp, lm, rf oraz xg.

#wczytanie danych
dt <- read.csv2("http://dydaktyka.polsl.pl/roz6/towczarek/data017.csv", stringsAsFactors = TRUE)

#sprawdzenie danych
str(dt)
summary(dt)

#usuwamy wszystko poza 5-13
dt2 <- dt[,-c(1,3,4,14,15,16,17,18,19)]

#budowa modelu rpart
rp1 <- rpart(x2~., data = dt2)

#szybki wykresik drzew
plot(as.party(rp1))

pred <- predict(rp1)
table(pred)
lrn.rp1 <- lrn("regr.rpart")
task1 <- TaskRegr$new(id = "dt", backend = dt2, target = "x2")
lrn.rp1$train(task1)
pred.rp <- lrn.rp1$predict(task1)

pred.rp$score(msr("regr.mae"))

rp1

#inne algorytmy
lrn.lm <- lrn("regr.lm")
lrn.rf <- lrn("regr.ranger")
lrn.xg <- lrn("regr.xgboost", eta = 0.1, nrounds = 50, 
              objective = "reg:squarederror") # aby pozbyć się ostrzeżeń

#do xgboosta wypadałoby zmienić factory na numeric
str(dt2)

#nowy zbiór danych aby zmienić na numeric
dt3num <- dt2

#korygowanie danych
dt3num$x13 <- as.numeric(dt3num$x13)

#nowy task zawierający skorygowane dane
task2 <- TaskRegr$new(id = "dt3num", backend = dt3num, target = "x2")

# projekt benchmarku
set.seed(10)
design1 <- benchmark_grid(
  tasks = list(task2),
  learners = list(lrn.rp1, lrn.lm, lrn.rf, lrn.xg),
  resamplings = rsmp("cv")
)

#i lecimy z tematem
system.time(
  bmr1 <- benchmark(design1)
)

# wyniki dla mse
bmr1$aggregate()

#wyniki mse
#nr      resample_result task_id   learner_id resampling_id iters regr.mse
#1:  1 <ResampleResult[21]>  dt3num   regr.rpart            cv    10 2.959367
#:  2 <ResampleResult[21]>  dt3num      regr.lm            cv    10 2.764950
#3:  3 <ResampleResult[21]>  dt3num  regr.ranger            cv    10 1.320520
#4:  4 <ResampleResult[21]>  dt3num regr.xgboost            cv    10 1.410439

#wynik dla tego co potrzebujemy
bmr1$aggregate(msrs(list("regr.mae", "regr.rmse", "regr.mape")))

#wyniki dla mae, rmse, mape
#nr      resample_result task_id   learner_id resampling_id iters  regr.mae regr.rmse  regr.mape
#1:  1 <ResampleResult[21]>  dt3num   regr.rpart            cv    10 1.3207163  1.719338 0.02962808
#2:  2 <ResampleResult[21]>  dt3num      regr.lm            cv    10 1.2796162  1.661793 0.02871676
#3:  3 <ResampleResult[21]>  dt3num  regr.ranger            cv    10 0.7974195  1.146637 0.01797471
#4:  4 <ResampleResult[21]>  dt3num regr.xgboost            cv    10 0.8491827  1.185831 0.01891182


#można spróbować stroić np xgboosta, ale zajmuje to trochę czasu
set.seed(20)

# wybor przestrzeni przeszukiwanych parametrow
pars.xg <- ps(
  eta = p_dbl(lower = 0.01, upper = 0.2),
  nrounds = p_int(lower = 50, upper = 500),
  gamma = p_dbl(lower = 0, upper = 3),
  subsample = p_dbl(lower = 0.7, upper = 1)
)

# instancja definiujaca strojenie
instance.xg <- TuningInstanceSingleCrit$new(
  task = task2,
  learner = lrn("regr.xgboost", objective = "reg:squarederror", nthread = 1),
  resampling = rsmp("cv", folds = 10),
  measure = msr("regr.mae"), #tu można zmienic na inne gówna
  search_space = pars.xg,
  terminator = trm("evals", n_evals = 30)
)

# wybor tunera - losowy
tuner.xg <- tnr("random_search")

# strojenie
system.time(
  tuner.xg$optimize(instance.xg)
)

# wyniki - parametry i blad
instance.xg$result

#                               eta       nrounds      gamma subsample learner_param_vals  x_domain regr.mse 
#INFO  [22:08:12.372] [bbotk]  0.0849329     290 0.02604911 0.8820071          <list[7]> <list[4]> 1.008123


#chyba to ma być tak tylko na innych predyktorach
# 1 #### 
# Zbuduj model liniowy, w którym zmienna celu to x1 a predyktory to zmienne # x3 - x7 i x19. Za pomocą tego modelu dokonaj predykcji na danych treningowych # 

# 2 #### # Porównaj za pomocą kroswalidacji wcześniejszy model liniowy z modelem random # forest na podstawie błędu MAPE. Predyktorami w tym drugim modelu też mają być
dt5 <- read.csv2("http://dydaktyka.polsl.pl/roz6/towczarek/data017.csv", stringsAsFactors = TRUE)

str(dt5)
summary(dt5)
pp <- dt5[,-c(2,8:18)]

set.seed(10)

lrn.lm <- lrn("regr.lm")
task1 <- TaskRegr$new(id = "pp", backend = pp, target = "x1")
lrn.lm$train(task1)
pred.lm <- lrn.lm$predict(task1)
pred.lm$score(msr("regr.mape"))
lrn.lm$model

set.seed(10)
lrn.rf <- lrn("regr.ranger")
lrn.rf$train(task1)
pred.rf <- lrn.rf$predict(task1)
pred.rf$score(msr("regr.mape"))


design1 <- benchmark_grid(
  tasks = task1,
  learners = list(lrn.rf, lrn.lm),
  resamplings = rsmp("cv")
)

bmr1 <- benchmark(design1)

bmr1$aggregate(msrs(list("regr.mape")))
